{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.generator import SEMamba\n",
    "import torch\n",
    "from utils.util import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Inference Process..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Initializing Inference Process..')\n",
    "# 修改 config 為有效的 YAML 配置文件路徑\n",
    "config = '/disk4/chocho/SEMamba/exp/20250403-SEMamba_v1_PCS-h32-tf2/config.yaml'  # 替換為實際的 YAML 檔案路徑\n",
    "checkpoint_file = '/disk4/chocho/SEMamba/exp/20250403-SEMamba_v1_PCS-h32-tf2/g_00078000.pth'\n",
    "\n",
    "global device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    #device = torch.device('cpu')\n",
    "    raise RuntimeError(\"Currently, CPU mode is not supported.\")\n",
    "\n",
    "cfg = load_config(config)\n",
    "model = SEMamba(cfg).to(device)\n",
    "state_dict = torch.load(checkpoint_file, map_location=device)\n",
    "model.load_state_dict(state_dict['generator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEMamba(\n",
       "  (dense_encoder): DenseEncoder(\n",
       "    (dense_conv_1): Sequential(\n",
       "      (0): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (dense_block): DenseBlock(\n",
       "      (dense_block): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (2): PReLU(num_parameters=32)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 1), dilation=(2, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (2): PReLU(num_parameters=32)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 1), dilation=(4, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (2): PReLU(num_parameters=32)\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 1), dilation=(8, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (2): PReLU(num_parameters=32)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dense_conv_2): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(1, 3), stride=(1, 2))\n",
       "      (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): PReLU(num_parameters=32)\n",
       "    )\n",
       "  )\n",
       "  (TSMamba): ModuleList(\n",
       "    (0-1): 2 x TFMambaBlock(\n",
       "      (time_mamba): MambaBlock(\n",
       "        (forward_blocks): ModuleList(\n",
       "          (0): Block(\n",
       "            (mixer): Mamba(\n",
       "              (in_proj): Linear(in_features=32, out_features=256, bias=False)\n",
       "              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
       "              (act): SiLU()\n",
       "              (x_proj): Linear(in_features=128, out_features=34, bias=False)\n",
       "              (dt_proj): Linear(in_features=2, out_features=128, bias=True)\n",
       "              (out_proj): Linear(in_features=128, out_features=32, bias=False)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (backward_blocks): ModuleList(\n",
       "          (0): Block(\n",
       "            (mixer): Mamba(\n",
       "              (in_proj): Linear(in_features=32, out_features=256, bias=False)\n",
       "              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
       "              (act): SiLU()\n",
       "              (x_proj): Linear(in_features=128, out_features=34, bias=False)\n",
       "              (dt_proj): Linear(in_features=2, out_features=128, bias=True)\n",
       "              (out_proj): Linear(in_features=128, out_features=32, bias=False)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (freq_mamba): MambaBlock(\n",
       "        (forward_blocks): ModuleList(\n",
       "          (0): Block(\n",
       "            (mixer): Mamba(\n",
       "              (in_proj): Linear(in_features=32, out_features=256, bias=False)\n",
       "              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
       "              (act): SiLU()\n",
       "              (x_proj): Linear(in_features=128, out_features=34, bias=False)\n",
       "              (dt_proj): Linear(in_features=2, out_features=128, bias=True)\n",
       "              (out_proj): Linear(in_features=128, out_features=32, bias=False)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (backward_blocks): ModuleList(\n",
       "          (0): Block(\n",
       "            (mixer): Mamba(\n",
       "              (in_proj): Linear(in_features=32, out_features=256, bias=False)\n",
       "              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
       "              (act): SiLU()\n",
       "              (x_proj): Linear(in_features=128, out_features=34, bias=False)\n",
       "              (dt_proj): Linear(in_features=2, out_features=128, bias=True)\n",
       "              (out_proj): Linear(in_features=128, out_features=32, bias=False)\n",
       "            )\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (tlinear): ConvTranspose1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "      (flinear): ConvTranspose1d(64, 32, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (mask_decoder): MagDecoder(\n",
       "    (dense_block): DenseBlock(\n",
       "      (dense_block): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (2): PReLU(num_parameters=32)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 1), dilation=(2, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (2): PReLU(num_parameters=32)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 1), dilation=(4, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (2): PReLU(num_parameters=32)\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 1), dilation=(8, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (2): PReLU(num_parameters=32)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mask_conv): Sequential(\n",
       "      (0): ConvTranspose2d(32, 32, kernel_size=(1, 3), stride=(1, 2))\n",
       "      (1): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (3): PReLU(num_parameters=1)\n",
       "      (4): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (lsigmoid): LearnableSigmoid2D()\n",
       "  )\n",
       "  (phase_decoder): PhaseDecoder(\n",
       "    (dense_block): DenseBlock(\n",
       "      (dense_block): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (2): PReLU(num_parameters=32)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 1), dilation=(2, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (2): PReLU(num_parameters=32)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 1), dilation=(4, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (2): PReLU(num_parameters=32)\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 1), dilation=(8, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (2): PReLU(num_parameters=32)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (phase_conv): Sequential(\n",
       "      (0): ConvTranspose2d(32, 32, kernel_size=(1, 3), stride=(1, 2))\n",
       "      (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (phase_conv_r): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (phase_conv_i): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "\n",
    "# 假設你的模型是 `model`\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disk4/chocho/SEMamba/_202505\n"
     ]
    }
   ],
   "source": [
    "cd _202505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dense_encoder.dense_conv_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block(\n",
       "  (mixer): Mamba(\n",
       "    (in_proj): Linear(in_features=32, out_features=256, bias=False)\n",
       "    (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
       "    (act): SiLU()\n",
       "    (x_proj): Linear(in_features=128, out_features=34, bias=False)\n",
       "    (dt_proj): Linear(in_features=2, out_features=128, bias=True)\n",
       "    (out_proj): Linear(in_features=128, out_features=32, bias=False)\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.TSMamba[0].time_mamba.forward_blocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B,L,D: (1, 2, 286, 201)\n"
     ]
    }
   ],
   "source": [
    "# 定義輸入張量的形狀 (dummy input)\n",
    "shape = 1,2,286,201\n",
    "print(\"B,L,D:\", shape)\n",
    "dummy_input = torch.randn(shape).to(\"cuda\")\n",
    "# dummy_input = (torch.randn(batch, length, dim).to(\"cuda\"),\n",
    "            #    torch.randn(batch, length, dim).to(\"cuda\"))\n",
    "\n",
    "# 導出 ONNX 模型\n",
    "torch.onnx.export(\n",
    "    model.dense_encoder.dense_conv_1[0],\n",
    "    dummy_input,               # 輸入範例\n",
    "    \"onnx_files/dense_encoder-dense_conv_1.onnx\",              # 輸出檔案名稱\n",
    "    input_names=[\"input\"],     # 輸入層名稱\n",
    "    output_names=[\"output\"],   # 輸出層名稱\n",
    "    dynamic_axes={             # 支援動態形狀（可選）\n",
    "        \"input\": {0: \"batch_size\"},\n",
    "        \"output\": {0: \"batch_size\"}\n",
    "    },\n",
    "    opset_version=11           # ONNX 操作集版本，常用 11 或更高\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B,L,D: (100, 286, 32)\n"
     ]
    }
   ],
   "source": [
    "# 定義輸入張量的形狀 (dummy input)\n",
    "shape = 100,286,32\n",
    "print(\"B,L,D:\", shape)\n",
    "dummy_input = torch.randn(shape).to(\"cuda\")\n",
    "# dummy_input = (torch.randn(batch, length, dim).to(\"cuda\"),\n",
    "            #    torch.randn(batch, length, dim).to(\"cuda\"))\n",
    "\n",
    "# 導出 ONNX 模型\n",
    "torch.onnx.export(\n",
    "    model.TSMamba[0].time_mamba.forward_blocks[0].mixer,\n",
    "    dummy_input,               # 輸入範例\n",
    "    \"onnx_files/time_mamba-Mamba.onnx\",              # 輸出檔案名稱\n",
    "    input_names=[\"input\"],     # 輸入層名稱\n",
    "    output_names=[\"output\"],   # 輸出層名稱\n",
    "    dynamic_axes={             # 支援動態形狀（可選）\n",
    "        \"input\": {0: \"batch_size\"},\n",
    "        \"output\": {0: \"batch_size\"}\n",
    "    },\n",
    "    opset_version=11           # ONNX 操作集版本，常用 11 或更高\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B,L,D: (100, 286, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/mamba_ssm/ops/triton/layernorm.py:409: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  else (torch.float32 if residual_in_fp32 else None)\n",
      "/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/mamba_ssm/ops/triton/layernorm.py:133: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert weight.shape == (N,)\n",
      "/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/mamba_ssm/ops/triton/layernorm.py:150: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  BLOCK_N = min(MAX_FUSED_SIZE, triton.next_power_of_2(N))\n",
      "/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/mamba_ssm/ops/triton/layernorm.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if N > BLOCK_N:\n"
     ]
    },
    {
     "ename": "CompilationError",
     "evalue": "at 31:24:    HAS_BIAS: tl.constexpr,\n):\n    # Map the program id to the row of X and Y it should compute.\n    row = tl.program_id(0)\n    X += row * stride_x_row\n    Y += row * stride_y_row\n    if HAS_RESIDUAL:\n        RESIDUAL += row * stride_res_row\n    if STORE_RESIDUAL_OUT:\n        RESIDUAL_OUT += row * stride_res_out_row\n    # Compute mean and variance\n    cols = tl.arange(0, BLOCK_N)\n                        ^\nValueError(\"arange's arguments must be of type tl.constexpr\")",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/compiler/code_generator.py:1124\u001b[39m, in \u001b[36mast_to_ttir\u001b[39m\u001b[34m(fn, signature, specialization, constants, debug, arch)\u001b[39m\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CompilationError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/compiler/code_generator.py:1017\u001b[39m, in \u001b[36mCodeGenerator.visit\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m   1016\u001b[39m     last_loc = \u001b[38;5;28mself\u001b[39m.builder.get_loc()\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m ret = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[38;5;66;03m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/ast.py:418\u001b[39m, in \u001b[36mNodeVisitor.visit\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    417\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, \u001b[38;5;28mself\u001b[39m.generic_visit)\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/compiler/code_generator.py:293\u001b[39m, in \u001b[36mCodeGenerator.visit_Module\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisit_Module\u001b[39m(\u001b[38;5;28mself\u001b[39m, node):\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[43mast\u001b[49m\u001b[43m.\u001b[49m\u001b[43mNodeVisitor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgeneric_visit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/ast.py:426\u001b[39m, in \u001b[36mNodeVisitor.generic_visit\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    425\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, AST):\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, AST):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/compiler/code_generator.py:1017\u001b[39m, in \u001b[36mCodeGenerator.visit\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m   1016\u001b[39m     last_loc = \u001b[38;5;28mself\u001b[39m.builder.get_loc()\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m ret = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[38;5;66;03m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/ast.py:418\u001b[39m, in \u001b[36mNodeVisitor.visit\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    417\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, \u001b[38;5;28mself\u001b[39m.generic_visit)\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/compiler/code_generator.py:362\u001b[39m, in \u001b[36mCodeGenerator.visit_FunctionDef\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;66;03m# visit function body\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvisit_compound_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[38;5;66;03m# finalize function\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/compiler/code_generator.py:288\u001b[39m, in \u001b[36mCodeGenerator.visit_compound_statement\u001b[39m\u001b[34m(self, stmts)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m stmt \u001b[38;5;129;01min\u001b[39;00m stmts:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     ret_type = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ret_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stmt, ast.Return):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/compiler/code_generator.py:1017\u001b[39m, in \u001b[36mCodeGenerator.visit\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m   1016\u001b[39m     last_loc = \u001b[38;5;28mself\u001b[39m.builder.get_loc()\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m ret = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[38;5;66;03m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/ast.py:418\u001b[39m, in \u001b[36mNodeVisitor.visit\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    417\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, \u001b[38;5;28mself\u001b[39m.generic_visit)\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/compiler/code_generator.py:414\u001b[39m, in \u001b[36mCodeGenerator.visit_Assign\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    413\u001b[39m names = _names[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(names, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/compiler/code_generator.py:1017\u001b[39m, in \u001b[36mCodeGenerator.visit\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m   1016\u001b[39m     last_loc = \u001b[38;5;28mself\u001b[39m.builder.get_loc()\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m ret = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[38;5;66;03m# Reset the location to the last one before the visit\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/ast.py:418\u001b[39m, in \u001b[36mNodeVisitor.visit\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    417\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, \u001b[38;5;28mself\u001b[39m.generic_visit)\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/compiler/code_generator.py:946\u001b[39m, in \u001b[36mCodeGenerator.visit_Call\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    945\u001b[39m         extra_kwargs[\u001b[33m'\u001b[39m\u001b[33m_generator\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkws\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_namespace.values():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/language/core.py:30\u001b[39m, in \u001b[36mbuiltin.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     27\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDid you forget to add @triton.jit ? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(`_builder` argument must be provided outside of JIT functions.)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/language/core.py:813\u001b[39m, in \u001b[36marange\u001b[39m\u001b[34m(start, end, _builder)\u001b[39m\n\u001b[32m    812\u001b[39m end = _constexpr_to_value(end)\n\u001b[32m--> \u001b[39m\u001b[32m813\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msemantic\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_builder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/language/semantic.py:485\u001b[39m, in \u001b[36marange\u001b[39m\u001b[34m(start, end, builder)\u001b[39m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(start, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(end, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33marange\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms arguments must be of type tl.constexpr\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    486\u001b[39m is_start_int64 = \u001b[38;5;28mbool\u001b[39m(start >> \u001b[32m32\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: arange's arguments must be of type tl.constexpr",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mCompilationError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m dummy_input = torch.randn(shape).to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 導出 ONNX 模型\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43monnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTSMamba\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime_mamba\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward_blocks\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# 輸入範例\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43monnx_files/time_mamba-norm.onnx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# 輸出檔案名稱\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# 輸入層名稱\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# 輸出層名稱\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# 支援動態形狀（可選）\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m11\u001b[39;49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# ONNX 操作集版本，常用 11 或更高\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/onnx/utils.py:516\u001b[39m, in \u001b[36mexport\u001b[39m\u001b[34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;129m@_beartype\u001b[39m.beartype\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexport\u001b[39m(\n\u001b[32m    191\u001b[39m     model: Union[torch.nn.Module, torch.jit.ScriptModule, torch.jit.ScriptFunction],\n\u001b[32m   (...)\u001b[39m\u001b[32m    208\u001b[39m     autograd_inlining: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    209\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    210\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[32m    211\u001b[39m \n\u001b[32m    212\u001b[39m \u001b[33;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    513\u001b[39m \u001b[33;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[32m    514\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/onnx/utils.py:1613\u001b[39m, in \u001b[36m_export\u001b[39m\u001b[34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[39m\n\u001b[32m   1610\u001b[39m     dynamic_axes = {}\n\u001b[32m   1611\u001b[39m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[32m-> \u001b[39m\u001b[32m1613\u001b[39m graph, params_dict, torch_out = \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1614\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[32m   1627\u001b[39m defer_weight_export = (\n\u001b[32m   1628\u001b[39m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states.ExportTypes.PROTOBUF_FILE\n\u001b[32m   1629\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/onnx/utils.py:1135\u001b[39m, in \u001b[36m_model_to_graph\u001b[39m\u001b[34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[39m\n\u001b[32m   1132\u001b[39m     args = (args,)\n\u001b[32m   1134\u001b[39m model = _pre_trace_quant_model(model, args)\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m graph, params, torch_out, module = \u001b[43m_create_jit_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1136\u001b[39m params_dict = _get_named_param_dict(graph, params)\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/onnx/utils.py:1011\u001b[39m, in \u001b[36m_create_jit_graph\u001b[39m\u001b[34m(model, args)\u001b[39m\n\u001b[32m   1006\u001b[39m     graph = _C._propagate_and_assign_input_shapes(\n\u001b[32m   1007\u001b[39m         graph, flattened_args, param_count_list, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1008\u001b[39m     )\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, params, torch_out, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m graph, torch_out = \u001b[43m_trace_and_get_graph_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1012\u001b[39m _C._jit_pass_onnx_lint(graph)\n\u001b[32m   1013\u001b[39m state_dict = torch.jit._unique_state_dict(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/onnx/utils.py:915\u001b[39m, in \u001b[36m_trace_and_get_graph_from_model\u001b[39m\u001b[34m(model, args)\u001b[39m\n\u001b[32m    913\u001b[39m prev_autocast_cache_enabled = torch.is_autocast_cache_enabled()\n\u001b[32m    914\u001b[39m torch.set_autocast_cache_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m trace_graph, torch_out, inputs_states = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjit\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_trace_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    922\u001b[39m torch.set_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[32m    924\u001b[39m warn_on_static_input_change(inputs_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/jit/_trace.py:1296\u001b[39m, in \u001b[36m_get_trace_graph\u001b[39m\u001b[34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[39m\n\u001b[32m   1294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m   1295\u001b[39m     args = (args,)\n\u001b[32m-> \u001b[39m\u001b[32m1296\u001b[39m outs = \u001b[43mONNXTracedModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/jit/_trace.py:138\u001b[39m, in \u001b[36mONNXTracedModule.forward\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(out_vars)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m graph, out = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_graph_by_tracing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43min_vars\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_create_interpreter_name_lookup_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return_inputs:\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, outs[\u001b[32m0\u001b[39m], ret_inputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/jit/_trace.py:129\u001b[39m, in \u001b[36mONNXTracedModule.forward.<locals>.wrapper\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return_inputs_states:\n\u001b[32m    128\u001b[39m     inputs_states.append(_unflatten(in_args, in_desc))\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m outs.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrace_inputs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return_inputs_states:\n\u001b[32m    131\u001b[39m     inputs_states[\u001b[32m0\u001b[39m] = (inputs_states[\u001b[32m0\u001b[39m], trace_inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[39m, in \u001b[36mModule._slow_forward\u001b[39m\u001b[34m(self, *input, **kwargs)\u001b[39m\n\u001b[32m   1499\u001b[39m         recording_scopes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1501\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1503\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/mamba_ssm/ops/triton/layernorm.py:494\u001b[39m, in \u001b[36mRMSNorm.forward\u001b[39m\u001b[34m(self, x, residual, prenorm, residual_in_fp32)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, residual=\u001b[38;5;28;01mNone\u001b[39;00m, prenorm=\u001b[38;5;28;01mFalse\u001b[39;00m, residual_in_fp32=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrms_norm_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprenorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprenorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresidual_in_fp32\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresidual_in_fp32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/mamba_ssm/ops/triton/layernorm.py:478\u001b[39m, in \u001b[36mrms_norm_fn\u001b[39m\u001b[34m(x, weight, bias, residual, prenorm, residual_in_fp32, eps)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrms_norm_fn\u001b[39m(x, weight, bias, residual=\u001b[38;5;28;01mNone\u001b[39;00m, prenorm=\u001b[38;5;28;01mFalse\u001b[39;00m, residual_in_fp32=\u001b[38;5;28;01mFalse\u001b[39;00m, eps=\u001b[32m1e-6\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLayerNormFn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprenorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual_in_fp32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/torch/autograd/function.py:553\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    551\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    552\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    556\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    557\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    558\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    559\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    560\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    561\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/mamba_ssm/ops/triton/layernorm.py:411\u001b[39m, in \u001b[36mLayerNormFn.forward\u001b[39m\u001b[34m(ctx, x, weight, bias, residual, eps, prenorm, residual_in_fp32, is_rms_norm)\u001b[39m\n\u001b[32m    405\u001b[39m     bias = bias.contiguous()\n\u001b[32m    406\u001b[39m residual_dtype = (\n\u001b[32m    407\u001b[39m     residual.dtype\n\u001b[32m    408\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m residual \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    409\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m (torch.float32 \u001b[38;5;28;01mif\u001b[39;00m residual_in_fp32 \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    410\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m y, mean, rstd, residual_out = \u001b[43m_layer_norm_fwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresidual_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_rms_norm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_rms_norm\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    414\u001b[39m ctx.save_for_backward(residual_out, weight, bias, mean, rstd)\n\u001b[32m    415\u001b[39m ctx.x_shape_og = x_shape_og\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/mamba_ssm/ops/triton/layernorm.py:155\u001b[39m, in \u001b[36m_layer_norm_fwd\u001b[39m\u001b[34m(x, weight, bias, eps, residual, out_dtype, residual_dtype, is_rms_norm)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# heuristics for number of warps\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.cuda.device(x.device.index):\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[43m_layer_norm_fwd_1pass_kernel\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresidual_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrstd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresidual_out\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresidual_out\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_rms_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mBLOCK_N\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresidual_out\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;66;03m# residual_out is None if residual is None and residual_dtype == input_dtype\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y, mean, rstd, residual_out \u001b[38;5;28;01mif\u001b[39;00m residual_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/runtime/autotuner.py:100\u001b[39m, in \u001b[36mAutotuner.run\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m pruned_configs = \u001b[38;5;28mself\u001b[39m.prune_configs(kwargs)\n\u001b[32m     99\u001b[39m bench_start = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m timings = \u001b[43m{\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bench\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m           \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpruned_configs\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    102\u001b[39m bench_end = time.time()\n\u001b[32m    103\u001b[39m \u001b[38;5;28mself\u001b[39m.bench_time = bench_end - bench_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/runtime/autotuner.py:100\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     98\u001b[39m pruned_configs = \u001b[38;5;28mself\u001b[39m.prune_configs(kwargs)\n\u001b[32m     99\u001b[39m bench_start = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m timings = {config: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bench\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m            \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m pruned_configs}\n\u001b[32m    102\u001b[39m bench_end = time.time()\n\u001b[32m    103\u001b[39m \u001b[38;5;28mself\u001b[39m.bench_time = bench_end - bench_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/runtime/autotuner.py:83\u001b[39m, in \u001b[36mAutotuner._bench\u001b[39m\u001b[34m(self, config, *args, **meta)\u001b[39m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mself\u001b[39m.fn.run(*args, num_warps=config.num_warps, num_stages=config.num_stages, **current)\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdo_bench\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwarmup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutOfResources:\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m), \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m), \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/testing.py:104\u001b[39m, in \u001b[36mdo_bench\u001b[39m\u001b[34m(fn, warmup, rep, grad_to_none, quantiles, fast_flush, return_mode)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[33;03mBenchmark the runtime of the provided function. By default, return the median runtime of :code:`fn` along with\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[33;03mthe 20-th and 80-th performance percentile.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m \u001b[33;03m:type fast_flush: bool\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m torch.cuda.synchronize()\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# We maintain a buffer of 256 MB that we clear\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# before each kernel call to make sure that the L2\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# doesn't contain any input data before the run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/runtime/autotuner.py:81\u001b[39m, in \u001b[36mAutotuner._bench.<locals>.kernel_call\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     79\u001b[39m     config.pre_hook(full_nargs)\n\u001b[32m     80\u001b[39m \u001b[38;5;28mself\u001b[39m.hook(args)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_warps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_warps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_stages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_stages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:63\u001b[39m, in \u001b[36m_layer_norm_fwd_1pass_kernel\u001b[39m\u001b[34m(X, Y, W, B, RESIDUAL, RESIDUAL_OUT, Mean, Rstd, stride_x_row, stride_y_row, stride_res_row, stride_res_out_row, N, eps, IS_RMS_NORM, BLOCK_N, HAS_RESIDUAL, STORE_RESIDUAL_OUT, HAS_BIAS, grid, num_warps, num_stages, extern_libs, stream, warmup, device, device_type)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/compiler/compiler.py:476\u001b[39m, in \u001b[36mcompile\u001b[39m\u001b[34m(fn, **kwargs)\u001b[39m\n\u001b[32m    474\u001b[39m path = metadata_group.get(ir_filename)\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m     next_module = \u001b[43mcompile_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ir == \u001b[33m\"\u001b[39m\u001b[33mamdgcn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    478\u001b[39m         extra_file_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.hsaco_path\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/compiler/compiler.py:381\u001b[39m, in \u001b[36mcompile.<locals>.<lambda>\u001b[39m\u001b[34m(src)\u001b[39m\n\u001b[32m    378\u001b[39m stages = \u001b[38;5;28mdict\u001b[39m()\n\u001b[32m    379\u001b[39m stages[\u001b[33m\"\u001b[39m\u001b[33mast\u001b[39m\u001b[33m\"\u001b[39m] = (\u001b[38;5;28;01mlambda\u001b[39;00m path: fn, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    380\u001b[39m stages[\u001b[33m\"\u001b[39m\u001b[33mttir\u001b[39m\u001b[33m\"\u001b[39m] = (\u001b[38;5;28;01mlambda\u001b[39;00m path: parse_mlir_module(path, context),\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m                   \u001b[38;5;28;01mlambda\u001b[39;00m src: optimize_ttir(\u001b[43mast_to_ttir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march\u001b[49m\u001b[43m=\u001b[49m\u001b[43march\u001b[49m\u001b[43m)\u001b[49m, arch))\n\u001b[32m    382\u001b[39m stages[\u001b[33m\"\u001b[39m\u001b[33mttgir\u001b[39m\u001b[33m\"\u001b[39m] = (\u001b[38;5;28;01mlambda\u001b[39;00m path: parse_mlir_module(path, context),\n\u001b[32m    383\u001b[39m                    \u001b[38;5;28;01mlambda\u001b[39;00m src: optimize_ttgir(ttir_to_ttgir(src, num_warps), num_stages, arch))\n\u001b[32m    384\u001b[39m stages[\u001b[33m\"\u001b[39m\u001b[33mllir\u001b[39m\u001b[33m\"\u001b[39m] = (\u001b[38;5;28;01mlambda\u001b[39;00m path: Path(path).read_text(),\n\u001b[32m    385\u001b[39m                   \u001b[38;5;28;01mlambda\u001b[39;00m src: ttgir_to_llir(src, extern_libs, arch))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/disk4/chocho/speechbrain/.speechbrain/lib/python3.11/site-packages/triton/compiler/code_generator.py:1133\u001b[39m, in \u001b[36mast_to_ttir\u001b[39m\u001b[34m(fn, signature, specialization, constants, debug, arch)\u001b[39m\n\u001b[32m   1131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1132\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CompilationError(fn.src, node, \u001b[38;5;28mrepr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1134\u001b[39m ret = generator.module\n\u001b[32m   1135\u001b[39m \u001b[38;5;66;03m# module takes ownership of the context\u001b[39;00m\n",
      "\u001b[31mCompilationError\u001b[39m: at 31:24:    HAS_BIAS: tl.constexpr,\n):\n    # Map the program id to the row of X and Y it should compute.\n    row = tl.program_id(0)\n    X += row * stride_x_row\n    Y += row * stride_y_row\n    if HAS_RESIDUAL:\n        RESIDUAL += row * stride_res_row\n    if STORE_RESIDUAL_OUT:\n        RESIDUAL_OUT += row * stride_res_out_row\n    # Compute mean and variance\n    cols = tl.arange(0, BLOCK_N)\n                        ^\nValueError(\"arange's arguments must be of type tl.constexpr\")"
     ]
    }
   ],
   "source": [
    "# 定義輸入張量的形狀 (dummy input)\n",
    "shape = 100,286,32\n",
    "print(\"B,L,D:\", shape)\n",
    "dummy_input = torch.randn(shape).to(\"cuda\")\n",
    "\n",
    "# 導出 ONNX 模型\n",
    "torch.onnx.export(\n",
    "    model.TSMamba[0].time_mamba.forward_blocks[0].norm,\n",
    "    dummy_input,               # 輸入範例\n",
    "    \"onnx_files/time_mamba-RMSNorm.onnx\",              # 輸出檔案名稱\n",
    "    input_names=[\"input\"],     # 輸入層名稱\n",
    "    output_names=[\"output\"],   # 輸出層名稱\n",
    "    dynamic_axes={             # 支援動態形狀（可選）\n",
    "        \"input\": {0: \"batch_size\"},\n",
    "        \"output\": {0: \"batch_size\"}\n",
    "    },\n",
    "    opset_version=11           # ONNX 操作集版本，常用 11 或更高\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義輸入張量的形狀 (dummy input)\n",
    "shape = 100,286,32\n",
    "print(\"B,L,D:\", shape)\n",
    "dummy_input = torch.randn(shape).to(\"cuda\")\n",
    "# dummy_input = (torch.randn(batch, length, dim).to(\"cuda\"),\n",
    "            #    torch.randn(batch, length, dim).to(\"cuda\"))\n",
    "\n",
    "# 導出 ONNX 模型\n",
    "torch.onnx.export(\n",
    "    model.TSMamba[0].time_mamba.forward_blocks[0].mixer,\n",
    "    dummy_input,               # 輸入範例\n",
    "    \"onnx_files/time_mamba-Mamba.onnx\",              # 輸出檔案名稱\n",
    "    input_names=[\"input\"],     # 輸入層名稱\n",
    "    output_names=[\"output\"],   # 輸出層名稱\n",
    "    dynamic_axes={             # 支援動態形狀（可選）\n",
    "        \"input\": {0: \"batch_size\"},\n",
    "        \"output\": {0: \"batch_size\"}\n",
    "    },\n",
    "    opset_version=11           # ONNX 操作集版本，常用 11 或更高\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
